{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdc5952",
   "metadata": {
    "papermill": {
     "duration": 0.005383,
     "end_time": "2024-04-16T20:43:35.710850",
     "exception": false,
     "start_time": "2024-04-16T20:43:35.705467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"font-family:Comic Sans MS; color:#a6a4a1\">1. Guns - FasterRCNN DetectionðŸ”«</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37e115",
   "metadata": {
    "papermill": {
     "duration": 0.004396,
     "end_time": "2024-04-16T20:43:35.720316",
     "exception": false,
     "start_time": "2024-04-16T20:43:35.715920",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th><b>Attribute</b></th>\n",
    "            <th><b>Details</b></th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><b>Author</b></td>\n",
    "            <td><b>Muhammad Sibtain Ali</b></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>GitHub</td>\n",
    "            <td><a href=\"https://github.com/SibtainAli92\"><img src=\"https://img.shields.io/badge/GitHub-Profile-red?style=for-the-badge&logo=github\" alt=\"GitHub\"/></a></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LinkedIn</td>\n",
    "            <td><a href=\"https://www.linkedin.com/in/sibtain-ali-data-pro-4404ba2b8/\"><img src=\"https://img.shields.io/badge/LinkedIn-Profile-red?style=for-the-badge&logo=linkedin\" alt=\"LinkedIn\"/></a></td>\n",
    "        </tr>    \n",
    "        <tr>\n",
    "            <td>Facebook</td>\n",
    "            <td><a href=\"https://www.facebook.com/profile.php?id=61556741770711\"><img src=\"https://img.shields.io/badge/Facebook-Profile-red?style=for-the-badge&logo=facebook\" alt=\"Facebook\"/></a></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Gmail</td>\n",
    "            <td><a href=\"sibtainali.data.pro@gmail.comProfile image\n",
    "sibtainali.data.pro@gmail.com\"><img src=\"https://img.shields.io/badge/Gmail-Contact%20Me-green?style=for-the-badge&logo=gmail\" alt=\"Gmail\"/></a></td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605fedf2",
   "metadata": {
    "papermill": {
     "duration": 0.0043,
     "end_time": "2024-04-16T20:43:35.729176",
     "exception": false,
     "start_time": "2024-04-16T20:43:35.724876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"font-family:Comic Sans MS; color:#a6a4a1\">2. Import Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c5243f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:35.740679Z",
     "iopub.status.busy": "2024-04-16T20:43:35.740281Z",
     "iopub.status.idle": "2024-04-16T20:43:46.863195Z",
     "shell.execute_reply": "2024-04-16T20:43:46.861783Z"
    },
    "papermill": {
     "duration": 11.13258,
     "end_time": "2024-04-16T20:43:46.866319",
     "exception": false,
     "start_time": "2024-04-16T20:43:35.733739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.core.defchararray import join, mod\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import os\n",
    "import torch\n",
    "from torch._C import device\n",
    "from torch.autograd import grad_mode\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from PIL import Image\n",
    "from torchvision import transforms as torchtrans  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d80b09",
   "metadata": {
    "papermill": {
     "duration": 0.004398,
     "end_time": "2024-04-16T20:43:46.875574",
     "exception": false,
     "start_time": "2024-04-16T20:43:46.871176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"font-family:Comic Sans MS; color:#a6a4a1\">3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52225514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:46.887801Z",
     "iopub.status.busy": "2024-04-16T20:43:46.886619Z",
     "iopub.status.idle": "2024-04-16T20:43:46.893182Z",
     "shell.execute_reply": "2024-04-16T20:43:46.891744Z"
    },
    "papermill": {
     "duration": 0.015851,
     "end_time": "2024-04-16T20:43:46.896019",
     "exception": false,
     "start_time": "2024-04-16T20:43:46.880168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_path = '../input/guns-object-detection/Labels'\n",
    "imgs_path = '../input/guns-object-detection/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2ba1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:46.909045Z",
     "iopub.status.busy": "2024-04-16T20:43:46.908509Z",
     "iopub.status.idle": "2024-04-16T20:43:46.926708Z",
     "shell.execute_reply": "2024-04-16T20:43:46.925367Z"
    },
    "papermill": {
     "duration": 0.028593,
     "end_time": "2024-04-16T20:43:46.929565",
     "exception": false,
     "start_time": "2024-04-16T20:43:46.900972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class gun(Dataset):\n",
    "    def __init__(self,imgs_path,labels_path):\n",
    "\n",
    "        self.imgs_path = imgs_path\n",
    "        self.labels_path = labels_path\n",
    "        #from the path,made lists of images & labels' name\n",
    "        self.img_name = [img for img in sorted(os.listdir(self.imgs_path))]\n",
    "        self.label_name = [label for label in sorted(os.listdir(self.labels_path))]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        image_path = os.path.join(self.imgs_path,str(self.img_name[idx]))\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        img_res = img_rgb/255\n",
    "        img_res = torch.as_tensor(img_res).to(device)\n",
    "        img_res = img_res.permute(2, 0, 1)\n",
    "        \n",
    "        label_name = self.img_name[idx][:-4] + \"txt\"\n",
    "        label_path = os.path.join(self.labels_path,str(label_name))\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            l_count = int(label_file.readline())\n",
    "            box = []\n",
    "            for i in range(l_count):\n",
    "                box.append(list(map(int, label_file.readline().split())))\n",
    "\n",
    "        target={}\n",
    "        target[\"boxes\"] = torch.as_tensor(box).to(device)\n",
    "        area = []\n",
    "        for i in range(len(box)):\n",
    "           \n",
    "            a = (box[i][2] - box[i][0]) * (box[i][3] - box[i][1])\n",
    "            area.append(a)\n",
    "        target[\"area\"] = torch.as_tensor(area).to(device)\n",
    "        labels = []\n",
    "        for i in range(len(box)):\n",
    "            labels.append(1)\n",
    "\n",
    "        target[\"image_id\"] = torch.as_tensor([idx]).to(device)\n",
    "        target[\"labels\"] = torch.as_tensor(labels, dtype = torch.int64).to(device)\n",
    "\n",
    "\n",
    "        return img_res,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b5b977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:46.941277Z",
     "iopub.status.busy": "2024-04-16T20:43:46.940779Z",
     "iopub.status.idle": "2024-04-16T20:43:46.947315Z",
     "shell.execute_reply": "2024-04-16T20:43:46.946312Z"
    },
    "papermill": {
     "duration": 0.015478,
     "end_time": "2024-04-16T20:43:46.949863",
     "exception": false,
     "start_time": "2024-04-16T20:43:46.934385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(num):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features, num)\n",
    "    return model\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f24370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:46.961769Z",
     "iopub.status.busy": "2024-04-16T20:43:46.961229Z",
     "iopub.status.idle": "2024-04-16T20:43:49.670965Z",
     "shell.execute_reply": "2024-04-16T20:43:49.669099Z"
    },
    "papermill": {
     "duration": 2.719455,
     "end_time": "2024-04-16T20:43:49.674238",
     "exception": false,
     "start_time": "2024-04-16T20:43:46.954783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160M/160M [00:01<00:00, 118MB/s]\n"
     ]
    }
   ],
   "source": [
    "gun_data = gun(imgs_path, labels_path)\n",
    "data_load = DataLoader(gun_data, batch_size=5,\n",
    "                       shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "num_class = 2\n",
    "model = model(num_class)\n",
    "model.to(device)\n",
    "num_epoch = 10\n",
    "param = [param for param in model.parameters() if param.requires_grad]\n",
    "optimizer = torch.optim.SGD(param,lr=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2814d541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:49.691236Z",
     "iopub.status.busy": "2024-04-16T20:43:49.690637Z",
     "iopub.status.idle": "2024-04-16T20:43:50.222033Z",
     "shell.execute_reply": "2024-04-16T20:43:50.220760Z"
    },
    "papermill": {
     "duration": 0.543488,
     "end_time": "2024-04-16T20:43:50.225555",
     "exception": false,
     "start_time": "2024-04-16T20:43:49.682067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "backbone.body.conv1.weight \t torch.Size([64, 3, 7, 7])\n",
      "backbone.body.bn1.weight \t torch.Size([64])\n",
      "backbone.body.bn1.bias \t torch.Size([64])\n",
      "backbone.body.bn1.running_mean \t torch.Size([64])\n",
      "backbone.body.bn1.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.0.conv1.weight \t torch.Size([64, 64, 1, 1])\n",
      "backbone.body.layer1.0.bn1.weight \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn1.bias \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn1.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn1.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.0.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "backbone.body.layer1.0.bn2.weight \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn2.bias \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn2.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.0.bn2.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.0.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "backbone.body.layer1.0.bn3.weight \t torch.Size([256])\n",
      "backbone.body.layer1.0.bn3.bias \t torch.Size([256])\n",
      "backbone.body.layer1.0.bn3.running_mean \t torch.Size([256])\n",
      "backbone.body.layer1.0.bn3.running_var \t torch.Size([256])\n",
      "backbone.body.layer1.0.downsample.0.weight \t torch.Size([256, 64, 1, 1])\n",
      "backbone.body.layer1.0.downsample.1.weight \t torch.Size([256])\n",
      "backbone.body.layer1.0.downsample.1.bias \t torch.Size([256])\n",
      "backbone.body.layer1.0.downsample.1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer1.0.downsample.1.running_var \t torch.Size([256])\n",
      "backbone.body.layer1.1.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "backbone.body.layer1.1.bn1.weight \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn1.bias \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn1.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn1.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.1.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "backbone.body.layer1.1.bn2.weight \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn2.bias \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn2.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.1.bn2.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.1.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "backbone.body.layer1.1.bn3.weight \t torch.Size([256])\n",
      "backbone.body.layer1.1.bn3.bias \t torch.Size([256])\n",
      "backbone.body.layer1.1.bn3.running_mean \t torch.Size([256])\n",
      "backbone.body.layer1.1.bn3.running_var \t torch.Size([256])\n",
      "backbone.body.layer1.2.conv1.weight \t torch.Size([64, 256, 1, 1])\n",
      "backbone.body.layer1.2.bn1.weight \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn1.bias \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn1.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn1.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.2.conv2.weight \t torch.Size([64, 64, 3, 3])\n",
      "backbone.body.layer1.2.bn2.weight \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn2.bias \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn2.running_mean \t torch.Size([64])\n",
      "backbone.body.layer1.2.bn2.running_var \t torch.Size([64])\n",
      "backbone.body.layer1.2.conv3.weight \t torch.Size([256, 64, 1, 1])\n",
      "backbone.body.layer1.2.bn3.weight \t torch.Size([256])\n",
      "backbone.body.layer1.2.bn3.bias \t torch.Size([256])\n",
      "backbone.body.layer1.2.bn3.running_mean \t torch.Size([256])\n",
      "backbone.body.layer1.2.bn3.running_var \t torch.Size([256])\n",
      "backbone.body.layer2.0.conv1.weight \t torch.Size([128, 256, 1, 1])\n",
      "backbone.body.layer2.0.bn1.weight \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn1.bias \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn1.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn1.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.0.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "backbone.body.layer2.0.bn2.weight \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn2.bias \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn2.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.0.bn2.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.0.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "backbone.body.layer2.0.bn3.weight \t torch.Size([512])\n",
      "backbone.body.layer2.0.bn3.bias \t torch.Size([512])\n",
      "backbone.body.layer2.0.bn3.running_mean \t torch.Size([512])\n",
      "backbone.body.layer2.0.bn3.running_var \t torch.Size([512])\n",
      "backbone.body.layer2.0.downsample.0.weight \t torch.Size([512, 256, 1, 1])\n",
      "backbone.body.layer2.0.downsample.1.weight \t torch.Size([512])\n",
      "backbone.body.layer2.0.downsample.1.bias \t torch.Size([512])\n",
      "backbone.body.layer2.0.downsample.1.running_mean \t torch.Size([512])\n",
      "backbone.body.layer2.0.downsample.1.running_var \t torch.Size([512])\n",
      "backbone.body.layer2.1.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "backbone.body.layer2.1.bn1.weight \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn1.bias \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn1.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn1.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.1.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "backbone.body.layer2.1.bn2.weight \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn2.bias \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn2.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.1.bn2.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.1.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "backbone.body.layer2.1.bn3.weight \t torch.Size([512])\n",
      "backbone.body.layer2.1.bn3.bias \t torch.Size([512])\n",
      "backbone.body.layer2.1.bn3.running_mean \t torch.Size([512])\n",
      "backbone.body.layer2.1.bn3.running_var \t torch.Size([512])\n",
      "backbone.body.layer2.2.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "backbone.body.layer2.2.bn1.weight \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn1.bias \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn1.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn1.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.2.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "backbone.body.layer2.2.bn2.weight \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn2.bias \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn2.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.2.bn2.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.2.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "backbone.body.layer2.2.bn3.weight \t torch.Size([512])\n",
      "backbone.body.layer2.2.bn3.bias \t torch.Size([512])\n",
      "backbone.body.layer2.2.bn3.running_mean \t torch.Size([512])\n",
      "backbone.body.layer2.2.bn3.running_var \t torch.Size([512])\n",
      "backbone.body.layer2.3.conv1.weight \t torch.Size([128, 512, 1, 1])\n",
      "backbone.body.layer2.3.bn1.weight \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn1.bias \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn1.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn1.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.3.conv2.weight \t torch.Size([128, 128, 3, 3])\n",
      "backbone.body.layer2.3.bn2.weight \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn2.bias \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn2.running_mean \t torch.Size([128])\n",
      "backbone.body.layer2.3.bn2.running_var \t torch.Size([128])\n",
      "backbone.body.layer2.3.conv3.weight \t torch.Size([512, 128, 1, 1])\n",
      "backbone.body.layer2.3.bn3.weight \t torch.Size([512])\n",
      "backbone.body.layer2.3.bn3.bias \t torch.Size([512])\n",
      "backbone.body.layer2.3.bn3.running_mean \t torch.Size([512])\n",
      "backbone.body.layer2.3.bn3.running_var \t torch.Size([512])\n",
      "backbone.body.layer3.0.conv1.weight \t torch.Size([256, 512, 1, 1])\n",
      "backbone.body.layer3.0.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.0.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.0.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.0.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.0.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.0.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.0.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.0.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.0.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.0.downsample.0.weight \t torch.Size([1024, 512, 1, 1])\n",
      "backbone.body.layer3.0.downsample.1.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.0.downsample.1.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.0.downsample.1.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.0.downsample.1.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.1.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.body.layer3.1.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.1.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.1.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.1.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.1.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.1.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.1.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.1.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.1.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.2.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.body.layer3.2.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.2.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.2.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.2.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.2.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.2.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.2.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.2.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.2.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.3.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.body.layer3.3.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.3.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.3.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.3.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.3.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.3.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.3.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.3.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.3.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.4.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.body.layer3.4.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.4.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.4.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.4.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.4.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.4.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.4.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.4.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.4.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer3.5.conv1.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.body.layer3.5.bn1.weight \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn1.bias \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn1.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn1.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.5.conv2.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.body.layer3.5.bn2.weight \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn2.bias \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn2.running_mean \t torch.Size([256])\n",
      "backbone.body.layer3.5.bn2.running_var \t torch.Size([256])\n",
      "backbone.body.layer3.5.conv3.weight \t torch.Size([1024, 256, 1, 1])\n",
      "backbone.body.layer3.5.bn3.weight \t torch.Size([1024])\n",
      "backbone.body.layer3.5.bn3.bias \t torch.Size([1024])\n",
      "backbone.body.layer3.5.bn3.running_mean \t torch.Size([1024])\n",
      "backbone.body.layer3.5.bn3.running_var \t torch.Size([1024])\n",
      "backbone.body.layer4.0.conv1.weight \t torch.Size([512, 1024, 1, 1])\n",
      "backbone.body.layer4.0.bn1.weight \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn1.bias \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn1.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn1.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.0.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.body.layer4.0.bn2.weight \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn2.bias \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn2.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.0.bn2.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.0.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "backbone.body.layer4.0.bn3.weight \t torch.Size([2048])\n",
      "backbone.body.layer4.0.bn3.bias \t torch.Size([2048])\n",
      "backbone.body.layer4.0.bn3.running_mean \t torch.Size([2048])\n",
      "backbone.body.layer4.0.bn3.running_var \t torch.Size([2048])\n",
      "backbone.body.layer4.0.downsample.0.weight \t torch.Size([2048, 1024, 1, 1])\n",
      "backbone.body.layer4.0.downsample.1.weight \t torch.Size([2048])\n",
      "backbone.body.layer4.0.downsample.1.bias \t torch.Size([2048])\n",
      "backbone.body.layer4.0.downsample.1.running_mean \t torch.Size([2048])\n",
      "backbone.body.layer4.0.downsample.1.running_var \t torch.Size([2048])\n",
      "backbone.body.layer4.1.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "backbone.body.layer4.1.bn1.weight \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn1.bias \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn1.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn1.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.1.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.body.layer4.1.bn2.weight \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn2.bias \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn2.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.1.bn2.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.1.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "backbone.body.layer4.1.bn3.weight \t torch.Size([2048])\n",
      "backbone.body.layer4.1.bn3.bias \t torch.Size([2048])\n",
      "backbone.body.layer4.1.bn3.running_mean \t torch.Size([2048])\n",
      "backbone.body.layer4.1.bn3.running_var \t torch.Size([2048])\n",
      "backbone.body.layer4.2.conv1.weight \t torch.Size([512, 2048, 1, 1])\n",
      "backbone.body.layer4.2.bn1.weight \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn1.bias \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn1.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn1.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.2.conv2.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.body.layer4.2.bn2.weight \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn2.bias \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn2.running_mean \t torch.Size([512])\n",
      "backbone.body.layer4.2.bn2.running_var \t torch.Size([512])\n",
      "backbone.body.layer4.2.conv3.weight \t torch.Size([2048, 512, 1, 1])\n",
      "backbone.body.layer4.2.bn3.weight \t torch.Size([2048])\n",
      "backbone.body.layer4.2.bn3.bias \t torch.Size([2048])\n",
      "backbone.body.layer4.2.bn3.running_mean \t torch.Size([2048])\n",
      "backbone.body.layer4.2.bn3.running_var \t torch.Size([2048])\n",
      "backbone.fpn.inner_blocks.0.0.weight \t torch.Size([256, 256, 1, 1])\n",
      "backbone.fpn.inner_blocks.0.0.bias \t torch.Size([256])\n",
      "backbone.fpn.inner_blocks.1.0.weight \t torch.Size([256, 512, 1, 1])\n",
      "backbone.fpn.inner_blocks.1.0.bias \t torch.Size([256])\n",
      "backbone.fpn.inner_blocks.2.0.weight \t torch.Size([256, 1024, 1, 1])\n",
      "backbone.fpn.inner_blocks.2.0.bias \t torch.Size([256])\n",
      "backbone.fpn.inner_blocks.3.0.weight \t torch.Size([256, 2048, 1, 1])\n",
      "backbone.fpn.inner_blocks.3.0.bias \t torch.Size([256])\n",
      "backbone.fpn.layer_blocks.0.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.fpn.layer_blocks.0.0.bias \t torch.Size([256])\n",
      "backbone.fpn.layer_blocks.1.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.fpn.layer_blocks.1.0.bias \t torch.Size([256])\n",
      "backbone.fpn.layer_blocks.2.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.fpn.layer_blocks.2.0.bias \t torch.Size([256])\n",
      "backbone.fpn.layer_blocks.3.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.fpn.layer_blocks.3.0.bias \t torch.Size([256])\n",
      "rpn.head.conv.0.0.weight \t torch.Size([256, 256, 3, 3])\n",
      "rpn.head.conv.0.0.bias \t torch.Size([256])\n",
      "rpn.head.cls_logits.weight \t torch.Size([3, 256, 1, 1])\n",
      "rpn.head.cls_logits.bias \t torch.Size([3])\n",
      "rpn.head.bbox_pred.weight \t torch.Size([12, 256, 1, 1])\n",
      "rpn.head.bbox_pred.bias \t torch.Size([12])\n",
      "roi_heads.box_head.fc6.weight \t torch.Size([1024, 12544])\n",
      "roi_heads.box_head.fc6.bias \t torch.Size([1024])\n",
      "roi_heads.box_head.fc7.weight \t torch.Size([1024, 1024])\n",
      "roi_heads.box_head.fc7.bias \t torch.Size([1024])\n",
      "roi_heads.box_predictor.cls_score.weight \t torch.Size([2, 1024])\n",
      "roi_heads.box_predictor.cls_score.bias \t torch.Size([2])\n",
      "roi_heads.box_predictor.bbox_pred.weight \t torch.Size([8, 1024])\n",
      "roi_heads.box_predictor.bbox_pred.bias \t torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc0076b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:50.243601Z",
     "iopub.status.busy": "2024-04-16T20:43:50.243134Z",
     "iopub.status.idle": "2024-04-16T20:43:50.252384Z",
     "shell.execute_reply": "2024-04-16T20:43:50.250542Z"
    },
    "papermill": {
     "duration": 0.02183,
     "end_time": "2024-04-16T20:43:50.255121",
     "exception": false,
     "start_time": "2024-04-16T20:43:50.233291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e444d379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T20:43:50.273227Z",
     "iopub.status.busy": "2024-04-16T20:43:50.271951Z",
     "iopub.status.idle": "2024-04-16T20:43:50.559636Z",
     "shell.execute_reply": "2024-04-16T20:43:50.558207Z"
    },
    "papermill": {
     "duration": 0.300311,
     "end_time": "2024-04-16T20:43:50.563113",
     "exception": false,
     "start_time": "2024-04-16T20:43:50.262802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "TRAINED_MODEL_VERSION = \"1.0a\"\n",
    "TRAINED_MODEL_FILENAME = \"weapon_trained_model-\"+TRAINED_MODEL_VERSION+\".pt\"\n",
    "torch.save(model, TRAINED_MODEL_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 114322,
     "sourceId": 272864,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.298738,
   "end_time": "2024-04-16T20:43:52.400833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-16T20:43:32.102095",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
